{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 280, 3)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# 打开HDF5文件\n",
    "f = h5py.File(\"C:\\\\Users\\\\Administrator\\\\Downloads\\\\hdf5_dm_july2021_1_to_200\\\\hdf5_dm_july2021_1.hdf5\", 'r')\n",
    "\n",
    "# 遍历文件中的所有数据集\n",
    "\n",
    "for key in f.keys():\n",
    "    #print(f[key].name)\n",
    "    if f[key].name == \"/frame_0_x\":\n",
    "        print(f[key].shape)\n",
    "        image = torch.tensor(f[key][:])\n",
    "        image = image.permute(2, 0, 1)\n",
    "        img_pil = transforms.ToPILImage()(image)\n",
    "        img_pil.show()\n",
    "        break\n",
    "    \n",
    "    #print(f[key].value)\n",
    "    #print(f[key].value)\n",
    "\n",
    "#print(len(f.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_steps': 178000, 'num_episodes': 178, 'is_static': False, 'counter_rew': Counter({0.0: 178000}), 'lengths': array([1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
      "       1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
      "       1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
      "       1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
      "       1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
      "       1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
      "       1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
      "       1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
      "       1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
      "       1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
      "       1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
      "       1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
      "       1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
      "       1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
      "       1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
      "       1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
      "       1000, 1000], dtype=int64), 'start_idx': array([     0,   1000,   2000,   3000,   4000,   5000,   6000,   7000,\n",
      "         8000,   9000,  10000,  11000,  12000,  13000,  14000,  15000,\n",
      "        16000,  17000,  18000,  19000,  20000,  21000,  22000,  23000,\n",
      "        24000,  25000,  26000,  27000,  28000,  29000,  30000,  31000,\n",
      "        32000,  33000,  34000,  35000,  36000,  37000,  38000,  39000,\n",
      "        40000,  41000,  42000,  43000,  44000,  45000,  46000,  47000,\n",
      "        48000,  49000,  50000,  51000,  52000,  53000,  54000,  55000,\n",
      "        56000,  57000,  58000,  59000,  60000,  61000,  62000,  63000,\n",
      "        64000,  65000,  66000,  67000,  68000,  69000,  70000,  71000,\n",
      "        72000,  73000,  74000,  75000,  76000,  77000,  78000,  79000,\n",
      "        80000,  81000,  82000,  83000,  84000,  85000,  86000,  87000,\n",
      "        88000,  89000,  90000,  91000,  92000,  93000,  94000,  95000,\n",
      "        96000,  97000,  98000,  99000, 100000, 101000, 102000, 103000,\n",
      "       104000, 105000, 106000, 107000, 108000, 109000, 110000, 111000,\n",
      "       112000, 113000, 114000, 115000, 116000, 117000, 118000, 119000,\n",
      "       120000, 121000, 122000, 123000, 124000, 125000, 126000, 127000,\n",
      "       128000, 129000, 130000, 131000, 132000, 133000, 134000, 135000,\n",
      "       136000, 137000, 138000, 139000, 140000, 141000, 142000, 143000,\n",
      "       144000, 145000, 146000, 147000, 148000, 149000, 150000, 151000,\n",
      "       152000, 153000, 154000, 155000, 156000, 157000, 158000, 159000,\n",
      "       160000, 161000, 162000, 163000, 164000, 165000, 166000, 167000,\n",
      "       168000, 169000, 170000, 171000, 172000, 173000, 174000, 175000,\n",
      "       176000, 177000], dtype=int64), 'counter_end': Counter({0: 178000})}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_12208\\563322154.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(\"C:\\\\Users\\\\Administrator\\\\Downloads\\\\out_dir\\\\low_res\\\\train\\\\info.pt\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.load(\"C:\\\\Users\\\\Administrator\\\\Downloads\\\\out_dir\\\\low_res\\\\train\\\\info.pt\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'JpegImageFile' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m      7\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(map_fn)\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#dataset = dataset.batch(batch_size=4)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#dataset = iter(dataset)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#print(next(dataset))\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\iterable_dataset.py:2093\u001b[0m, in \u001b[0;36mIterableDataset.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2090\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m formatter\u001b[38;5;241m.\u001b[39mformat_row(pa_table)\n\u001b[0;32m   2091\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m-> 2093\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mex_iterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2094\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mex_iterable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_typed\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2095\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# `IterableDataset` automatically fills missing columns with None.\u001b[39;49;00m\n\u001b[0;32m   2096\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# This is done with `_apply_feature_types_on_example`.\u001b[39;49;00m\n\u001b[0;32m   2097\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_apply_feature_types_on_example\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2098\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_token_per_repo_id\u001b[49m\n\u001b[0;32m   2099\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\iterable_dataset.py:1576\u001b[0m, in \u001b[0;36mTakeExamplesIterable.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1574\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1575\u001b[0m     ex_iterable_num_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_taken\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_dict \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1576\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey_example\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mex_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mex_iterable_num_taken\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1577\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state_dict\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1578\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_taken\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\iterable_dataset.py:1000\u001b[0m, in \u001b[0;36mMappedExamplesIterable.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    998\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m key, formatter\u001b[38;5;241m.\u001b[39mformat_row(pa_table)\n\u001b[0;32m    999\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1000\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter()\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\iterable_dataset.py:1091\u001b[0m, in \u001b[0;36mMappedExamplesIterable._iter\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1089\u001b[0m     function_args\u001b[38;5;241m.\u001b[39mappend(current_idx)\n\u001b[0;32m   1090\u001b[0m transformed_example \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(example)  \u001b[38;5;66;03m# this will be updated with the function output\u001b[39;00m\n\u001b[1;32m-> 1091\u001b[0m transformed_example\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunction_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;66;03m# then we remove the unwanted columns\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremove_columns:\n",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m, in \u001b[0;36mmap_fn\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_fn\u001b[39m(x):\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprevious_frame_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'JpegImageFile' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('fffffchopin/DiffusionDream_Dataset', streaming=True,split='train')\n",
    "def map_fn(x):\n",
    "    print(x['previous_frame_1'].shape)\n",
    "    return x\n",
    "dataset = dataset.map(map_fn)\n",
    "list(dataset.take(3))\n",
    "#dataset = dataset.batch(batch_size=4)\n",
    "#dataset = iter(dataset)\n",
    "#print(next(dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "single_array = [np.array([1, 2, 3])]\n",
    "result = np.concatenate(single_array)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/Administrator/Downloads/hdf5_dm_july2021_1_to_200'),\n",
       " WindowsPath('C:/Users/Administrator/Downloads/hdf5_dm_july2021_1_to_200.tar'),\n",
       " WindowsPath('C:/Users/Administrator/Downloads/Obsidian Vault'),\n",
       " WindowsPath('C:/Users/Administrator/Downloads/out_dir'),\n",
       " WindowsPath('C:/Users/Administrator/Downloads/tar_dir'),\n",
       " WindowsPath('C:/Users/Administrator/Downloads/~$系统实验二实验报告.doc')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "path = Path('C:\\\\Users\\\\Administrator\\\\Downloads')\n",
    "list(path.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\m'\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17312\\2946455888.py:2: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  target = np.load(\"E:\\\\huggingface_cache\\\\hub\\models--eloialonso--diamond\\\\blobs\\\\50e10ae563ce86e98c58de99c2d3a0a4c0f111f6fde2c87323bd1d5eb5210d1a\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 3, 30, 56])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "target = np.load(\"E:\\\\huggingface_cache\\\\hub\\models--eloialonso--diamond\\\\blobs\\\\50e10ae563ce86e98c58de99c2d3a0a4c0f111f6fde2c87323bd1d5eb5210d1a\")\n",
    "target = torch.tensor(target)\n",
    "target.unsqueeze(0).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
